{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mlflow\n",
    "from sklearn.metrics import log_loss, f1_score\n",
    "from pycaret.classification import setup, create_model, tune_model, predict_model\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# Initialize MLflow\n",
    "mlflow.set_experiment(\"Training\")\n",
    "\n",
    "# Load training and testing data\n",
    "original_data = pd.read_csv(\"./../Data/Raw/kobe_dataset.csv\")\n",
    "train_data = pd.read_parquet(\"./../Data/Modeling/base_train.parquet\")\n",
    "test_data = pd.read_parquet(\"./../Data/Modeling/base_test.parquet\")\n",
    "\n",
    "X_train = train_data.drop(\"shot_made_flag\", axis=1)\n",
    "y_train = train_data[\"shot_made_flag\"]\n",
    "\n",
    "X_test = test_data.drop(\"shot_made_flag\", axis=1)\n",
    "y_test = test_data[\"shot_made_flag\"]\n",
    "\n",
    "# Set up PyCaret environment\n",
    "clf_setup = setup(data=pd.concat([X_train, y_train], axis=1), n_jobs=-2, fold_shuffle=True, log_experiment=True, target=\"shot_made_flag\", experiment_name='Training')\n",
    "\n",
    "# Create and train Logistic Regression model\n",
    "lr_model = create_model(\"lr\", cross_validation=True, fold=5, verbose=False)\n",
    "\n",
    "# Make predictions on test set\n",
    "preds = predict_model(lr_model, data=X_test)\n",
    "\n",
    "# Calculate log loss\n",
    "loss = log_loss(y_test, preds['prediction_score'])\n",
    "\n",
    "# Log log loss to MLflow\n",
    "with mlflow.start_run(nested=True):\n",
    "    mlflow.log_metric(\"log_loss\", loss)\n",
    "    mlflow.end_run()\n",
    "\n",
    "# Choose the Random Forest Classifier classification algorithm and create the model\n",
    "rf_model = create_model(\"rf\")\n",
    "\n",
    "# Make predictions on test set\n",
    "preds = predict_model(rf_model, data=X_test)\n",
    "\n",
    "# Calculate log loss and F1_score\n",
    "loss = log_loss(y_test, preds[\"prediction_score\"])\n",
    "f1 = f1_score(y_test, preds[\"prediction_label\"])\n",
    "\n",
    "# Log log loss and F1_score to MLflow\n",
    "with mlflow.start_run(nested=True):\n",
    "    mlflow.log_metric(\"log_loss\", loss)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "    mlflow.end_run()\n",
    "\n",
    "# Register the model in MLflow\n",
    "mlflow.sklearn.log_model(rf_model, \"classifier\")\n",
    "print(\"Model saved in run %s\" % mlflow.active_run().info.run_uuid)\n",
    "\n",
    "# Serve the model using MLflow\n",
    "!mlflow models serve -m {model_uri} -p 1234 --no-conda &\n",
    "\n",
    "# Filter data for '3PT Field Goal'\n",
    "kobe_data_3pt = original_data[original_data['shot_type'] == '3PT Field Goal']\n",
    "\n",
    "# Prepare de new data\n",
    "X_new = kobe_data_3pt.drop(\"shot_made_flag\", axis=1)\n",
    "y_new = kobe_data_3pt[\"shot_made_flag\"]\n",
    "X_new.to_parquet(\"./../Data/Modeling/base_3pt.parquet\")\n",
    "\n",
    "# API\n",
    "data = X_new.to_json(orient=\"split\")\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "response = requests.post(\"http://127.0.0.1:1234/invocations\", data=data, headers=headers)\n",
    "\n",
    "predictions = pd.Series(json.loads(response.text))\n",
    "\n",
    "# Apply the trained model and calculate the log loss and F1_score\n",
    "log_loss_result = log_loss(y_new, predictions)\n",
    "f1_score_result = f1_score(y_new, predictions.round())\n",
    "\n",
    "print(f\"Log Loss: {log_loss_result}\")\n",
    "print(f\"F1 Score: {f1_score_result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_ops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9b38954e0605de1443d01b3c11fbef88dcf1b47437ce7691536bb5ebcb861cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
